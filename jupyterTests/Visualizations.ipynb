{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "The following code snippets are for creating all visualizations used in our presentation. This code can also be found within the *create_visualizations()* method from our _**sentiment\\_Analysis**_ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-eee1e2ce5bf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mourCode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msentiment_Analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create Object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Development\\ece143project\\ourCode\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msentimentAnalysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Development\\ece143project\\ourCode\\sentimentAnalysis.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# Handle imports and paths\n",
    "# Imports and path additions:\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from ourCode import sentiment_Analysis\n",
    "\n",
    "# Create Object\n",
    "sentimentObject = sentiment_Analysis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "For this notebook, we chose to use the load/store methods from our _**sentiment\\_Analysis**_ class to read in data that we had previously stored. This ensures that we can process online and using consistent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary with {name, party} and dictionary with {name, dirty Tweets}\n",
    "spDict = sentimentObject.get_data('loadData', fileName = \"../data/senateParty.txt\")\n",
    "stDict = sentimentObject.get_data('loadData', fileName = \"../data/senateTweets.tx\")\n",
    "\n",
    "# Clean dictionary\n",
    "stcDict = sentimentObject.scrape_tweet(tweetDict = stDict)\n",
    "\n",
    "# Analyze sentiment \n",
    "ssDict = sentimentObject.perform_sentiment_analysis(stcDict)\n",
    "\n",
    "# Seperate into democratic/republican dictionaries\n",
    "stcDDict = {}  # This is the dict containing all the Democrat senators and their clean tweets\n",
    "stcRDict = {}  # Republic senators and their clean tweets\n",
    "for key in stcDict:\n",
    "    if spDict[key] == 'D':\n",
    "        stcDDict[key] = stcDict[key]\n",
    "    elif spDict[key] == 'R':\n",
    "        stcRDict[key] = stcDict[key]\n",
    "\n",
    "sDDict = {}  # This is the dict containing all the Democrat senators and their sentiment scores\n",
    "sRDict = {}  # Republic senators adn their scores\n",
    "for key in ssDict:\n",
    "    if spDict[key] == 'D':\n",
    "        sDDict[key] = ssDict[key]\n",
    "    elif spDict[key] == 'R':\n",
    "        sRDict[key] = ssDict[key]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar plots\n",
    "Below is the code used to generate the bar plots of our presentation. These plots show the average sentiment value for each Twitter user specified in *115_Congress_House.csv*. The three plots created are democrat, republican and both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots\n",
    "#creat a list for only sentiment scores\n",
    "sslist = [v for v in ssDict.values()]\n",
    "sDlist = [v for v in sDDict.values()]\n",
    "sRlist = [v for v in sRDict.values()]\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(1)  # bar graph of all sentiment score and two parties separately\n",
    "plt.hist(sDlist,color='b',label='Democratic')\n",
    "plt.hist(sRlist,color='r',label='Republican')\n",
    "plt.xticks(np.arange(-2,7,0.5))\n",
    "plt.title('Sentiment score by party')\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('frequency')\n",
    "plt.legend(loc='upper right')\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.hist(sDlist,color='b',label='Democratic')\n",
    "plt.title('Sentiment score of the Democratic Party')\n",
    "plt.xticks(np.arange(-2,7,0.5))\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('frequency')\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.hist(sRlist,color='r',label='Republican')\n",
    "plt.xticks(np.arange(-2,7,0.5))\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Sentiment score of Republican Party')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics and Box plots\n",
    "The following code was used to gather statistics (mean, median, mode, etc.) and a box plot based on these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # (2)mean deviation,std,of two parties' score\n",
    "scoreD = [v for v in sDDict.values()]  # The score of Democratic party\n",
    "scoreR = [v for v in sDDict.values()]  # The score of Republic party\n",
    "print(scoreD)\n",
    "print(scoreR)\n",
    "\n",
    "D = array(scoreD)\n",
    "R = array(scoreR)\n",
    "col_labels = ['Democratic Party', 'Republican Party']\n",
    "row_labels = ['max', 'min', 'mean', 'median', 'mode', 'variance', 'std deviation']\n",
    "col_colors = ['blue', 'red']\n",
    "\n",
    "# get max, min, mean, median, mode, std for democrat and republican results\n",
    "max = [np.amax(D), np.amax(R)]\n",
    "min = [np.amin(D), np.amin(R)]\n",
    "mean = [np.mean(D), np.mean(R)]\n",
    "median = [np.median(D), np.median(R)]\n",
    "mode = [stats.mode(D)[0][0], stats.mode(R)[0][0]]\n",
    "variance = [np.var(D), np.var(R)]\n",
    "std = [np.std(D), np.std(R)]\n",
    "\n",
    "table_vals = np.around([max, min, mean, median, mode, variance, std], decimals=3)\n",
    "print(table_vals)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.table(cellText=table_vals, cellLoc='center',rowLabels=row_labels, colLabels=col_labels,\n",
    "          colColours=col_colors,colWidths=[0.4 for x in range(len(table_vals))], loc='best')\n",
    "plt.title('Statistics')\n",
    "plt.axis('off')\n",
    "\n",
    "# (3)box graph for two party\n",
    "labels = ['Democratic','Republican']\n",
    "color = dict(boxes = \"DarkGreen\", whiskers = \"DarkOrange\", medians = \"DarkBlue\", caps = \"Gray\")\n",
    "plt.figure(5)\n",
    "plt.boxplot([D,R],labels=labels,sym='o')\n",
    "plt.title('Box plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word clouds\n",
    "In order to generate the word clouds we needed text files with the tweets, the following code snippet produces the text files and creates the word clouds for each party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two txt files that only contains the clean tweets of two parties.\n",
    "afinn = Afinn()\n",
    "D = open('stcD.txt', 'w+',encoding='utf-8')\n",
    "for key in stcDDict:\n",
    "    for item in stcDDict[key]:\n",
    "        for element in item:\n",
    "            if afinn.score(element) != 0:\n",
    "                D.write(element)\n",
    "                D.write('\\n')\n",
    "\n",
    "D.close()\n",
    "\n",
    "R = open('stcR.txt', 'w+',encoding='utf-8')\n",
    "for key in stcRDict:\n",
    "    for item in stcRDict[key]:\n",
    "        for element in item:\n",
    "            if afinn.score(element) != 0:\n",
    "                R.write(element)\n",
    "                R.write('\\n')\n",
    "\n",
    "D.close()\n",
    "\n",
    "\n",
    "#word cloud for two parties\n",
    "plt.figure(6)\n",
    "textD = open(r'./stcD.txt','r').read()\n",
    "wcD = WordCloud(background_color='white', scale=1.5).generate(textD)\n",
    "plt.imshow(wcD)\n",
    "#plt.title('Word cloud of Democratic Party')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.figure(7)\n",
    "textR = open(r'./stcR.txt','r').read()\n",
    "wcR = WordCloud(background_color='white', scale=1.5).generate(textR)\n",
    "plt.imshow(wcR)\n",
    "#plt.title('Word cloud of Republican Party')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
